{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  remember original series vividly mostly due un...\n",
      "1  girlfight using wellknown formula someone poin...\n",
      "2  maybe wasnt good whole second episode first on...\n",
      "3  two thing haunt throughout lintrus intruder wh...\n",
      "4  couldnt believe put movie dvd player thought i...\n"
     ]
    }
   ],
   "source": [
    "# load in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# remove stop words and punctuation and html tags and lowercase\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove html tags\n",
    "    text = re.sub('<[^<]+?>', ' ', text)\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # remove stop words and lemmatize\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(text) if word.lower() not in stop_words])\n",
    "    return text.lower()\n",
    "\n",
    "# load in the data\n",
    "data = pd.DataFrame(columns=['text'])\n",
    "\n",
    "#navigate to folder\n",
    "# for file in os.listdir('aclImdb/train/unsup'):\n",
    "#     if file.endswith('.txt'):\n",
    "#         with open('aclImdb/train/unsup/' + file, 'r') as f:\n",
    "#             data.loc[len(data)] = preprocess_text(f.read())\n",
    "\n",
    "# load in the data\n",
    "data = pd.DataFrame(columns=[\"text\"])\n",
    "\n",
    "# navigate to folder\n",
    "for file in os.listdir(\"train/pos\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(\"train/pos/\" + file, \"r\") as f:\n",
    "            data.loc[len(data)] = preprocess_text(f.read())\n",
    "\n",
    "for file in os.listdir(\"train/neg\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(\"train/neg/\" + file, \"r\") as f:\n",
    "            data.loc[len(data)] = preprocess_text(f.read())\n",
    "\n",
    "# shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# load in the data\n",
    "test_data = pd.DataFrame(columns=[\"text\", \"sentiment\"])\n",
    "\n",
    "# navigate to folder\n",
    "for file in os.listdir(\"test/pos\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(\"test/pos/\" + file, \"r\") as f:\n",
    "            test_data.loc[len(data)] = [preprocess_text(f.read()), 1]\n",
    "\n",
    "for file in os.listdir(\"test/neg\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(\"test/neg/\" + file, \"r\") as f:\n",
    "            test_data.loc[len(data)] = [preprocess_text(f.read()), -1]\n",
    "\n",
    "# shuffle the data\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(test_data.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1)\n",
      "remember original series vividly mostly due unique blend wry humor macabre subject matter kolchak hardbitten newsman ben hecht school bigcity reporting gritty determination wiseass demeanor made even mundane episode eminently watchable personal fave spanish moss murders due totally original storyline poortroubled cajun youth louisiana bayou country take part sleep research experiment purpose dream analysis something go inexplicably wrong literally dream life swamp creature inhabiting dark folk tale youth malevolent manifestation seek person wronged dreamer conscious state brutally suffocates death kolchak investigates uncovers horrible truth much chagrin police captain joe mad dog siskawonderfully essayed grumpy keenan wynnand head sleep researcher played second city improv founder severn darden droll understated perfection wickedly funny harrowing finale take place chicago sewer system series highlight kolchak never got better timeless\n",
      "total positive reviews: 577\n",
      "total negative reviews: 239\n"
     ]
    }
   ],
   "source": [
    "#preprocess the training data\n",
    "print(data.shape)\n",
    "print(data.loc[0, 'text'])\n",
    "\n",
    "# set seed words\n",
    "pos_seed_words = ['good', 'great', 'excellent', 'amazing', 'awesome', 'fantastic', 'terrific', 'wonderful', 'superb', 'brilliant']\n",
    "neg_seed_words = ['bad', 'terrible', 'crap', 'useless', 'hate', 'horrible', 'awful', 'worst', 'boring', 'disgusting']\n",
    "\n",
    "# pos_seed_words = ['bad']\n",
    "# neg_seed_words = ['great']\n",
    "\n",
    "\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "\n",
    "#I have currently set the automatic sentiment analysis to be based on the number of seed words in the review\n",
    "# if there are 4 more positive seed words than negative seed words, the review is positive and vice versa\n",
    "# this gives about 1000 seeds and 3 takes it up to 2000\n",
    "diff_threshold = 4\n",
    "\n",
    "# # create a target variable\n",
    "# y = np.zeros(data.shape[0])\n",
    "# for i in range(data.shape[0]):\n",
    "#     pos_count = 0\n",
    "#     neg_count = 0\n",
    "#     for word in data.loc[i, 'text'].split():\n",
    "#         if word in pos_seed_words:\n",
    "#             pos_count += 1\n",
    "#         if word in neg_seed_words:\n",
    "#             neg_count += 1\n",
    "#     if pos_count - neg_count > diff_threshold:\n",
    "#         y[i] = 1\n",
    "#         num_pos += 1\n",
    "#         # print(i, \"positive\")\n",
    "#     elif neg_count - pos_count > diff_threshold:\n",
    "#         y[i] = -1\n",
    "#         num_neg += 1\n",
    "#         # print(i, \"negative\")\n",
    "\n",
    "#create a target variable\n",
    "y = np.zeros(data.shape[0])\n",
    "for i in range(data.shape[0]):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for word in data.loc[i, 'text'].split():\n",
    "        if word in pos_seed_words:\n",
    "            pos_count += 1\n",
    "        if word in neg_seed_words:\n",
    "            neg_count += 1\n",
    "    if pos_count > diff_threshold and neg_count == 0:\n",
    "        y[i] = 1\n",
    "        num_pos += 1\n",
    "        # print(i, \"positive\")\n",
    "    elif neg_count > diff_threshold and pos_count == 0:\n",
    "        y[i] = -1\n",
    "        num_neg += 1\n",
    "        # prin\n",
    "\n",
    "print(\"total positive reviews:\", num_pos)\n",
    "print(\"total negative reviews:\", num_neg)\n",
    "\n",
    "# add the target variable to the data\n",
    "data['sentiment'] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intend write review read default review show movie url felt compelled write rebuttal movie word superlative deserve slanderous review writer written think writer totally missed point movie large extent fact turned excessive show evangelist devotion occupied middle movie large extent however must beg differ reviewer movie end propaganda piece evangelist action think director shown religion enough find answer religion large extent incapable providing answer basic simple question one may ask religion offer sometimes banal platitude one kind another demonstrate value judgment religion remember religion transmuted expressed ordinary mostly well meaning basically good people usually monopoly truth thus religion end provide ultimate answer question life ultimately matter faith take faith thats given faith appreciate show faith given faith show faith tiresome thus time instructive note reviewer reaction movie case director show u one choose accept religious interpretation event answer question spite life go secret sunshine world awaits wounded soul regardless religious orientation thats core message film please note last scene movie dont get end movie great one thought provoking confronts viewer question answer thus work art challenging personally agree reviewer evangelical stuff bit much however given interpretation religion shown movie think director trying balance act whereby might called evangelist basher actor kangho song great always hes balanced perfect he amazing hes favorite korean actor doubt know actress doyeon jeon got cannes award best actress movie however find specialty acting seems get award act really convincingly cry hysterical scene great movie dont like please watch see get leaf dissatisfied uncomfortable asking question think director actually aiming movie first place\n",
      "good great excellent amazing awesome fantastic terrific wonderful superb brilliant\n",
      "bad terrible crap useless hate horrible awful worst boring disgusting\n",
      "good great excellent amazing awesome fantastic terrific wonderful superb brilliant\n",
      "bad terrible crap useless hate horrible awful worst boring disgusting\n"
     ]
    }
   ],
   "source": [
    "# print the first positive review\n",
    "print(data.loc[y == 1, 'text'].iloc[0])\n",
    "\n",
    "# test seed words to make sure they preprocess correctly\n",
    "pos_sentence = ' '.join(word for word in pos_seed_words)\n",
    "neg_sentence = ' '.join(word for word in neg_seed_words)\n",
    "\n",
    "print(pos_sentence)\n",
    "print(neg_sentence)\n",
    "\n",
    "preprocess_text(pos_sentence)\n",
    "preprocess_text(neg_sentence)\n",
    "\n",
    "print(pos_sentence)\n",
    "print(neg_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores [[0.01018496 0.98981504]\n",
      " [0.01018496 0.98981504]\n",
      " [0.01018496 0.98981504]\n",
      " ...\n",
      " [0.01018496 0.98981504]\n",
      " [0.01018496 0.98981504]\n",
      " [0.20514294 0.79485706]]\n",
      "Number of high confidence predictions: 22791\n",
      "scores [[0.80042283 0.19957717]\n",
      " [0.80042283 0.19957717]\n",
      " [0.80042283 0.19957717]\n",
      " ...\n",
      " [0.2        0.8       ]\n",
      " [0.80042283 0.19957717]\n",
      " [0.2        0.8       ]]\n",
      "Number of high confidence predictions: 22\n",
      "scores [[9.99296270e-01 7.03729768e-04]\n",
      " [9.99296270e-01 7.03729768e-04]\n",
      " [9.99296270e-01 7.03729768e-04]\n",
      " ...\n",
      " [2.41545894e-04 9.99758454e-01]\n",
      " [9.99296270e-01 7.03729768e-04]\n",
      " [2.41545894e-04 9.99758454e-01]]\n",
      "Number of high confidence predictions: 1370\n",
      "scores [[0.40022995 0.59977005]]\n",
      "Number of high confidence predictions: 0\n",
      "No high confidence predictions left 3\n"
     ]
    }
   ],
   "source": [
    "# create decision tree usingt seed sete\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "# create a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
    "\n",
    "# Wrap the decision tree in a calibrated classifier\n",
    "calibrated_clf = CalibratedClassifierCV(clf, method='isotonic')\n",
    "\n",
    "max_iterations = 10\n",
    "conf_thresh = 0.9\n",
    "\n",
    " # separate seed set from unlabelled set\n",
    "seed_set = data[data['sentiment'] != 0]\n",
    "unlabelled_set = data[data['sentiment'] == 0]\n",
    "\n",
    "X = seed_set['text']\n",
    "y = seed_set['sentiment']\n",
    "\n",
    "for i in range(max_iterations):\n",
    "\n",
    "    # vectorize the text\n",
    "    vector_X = vectorizer.fit_transform(X)\n",
    "    unlabelled_X = vectorizer.transform(unlabelled_set['text'])\n",
    "\n",
    "    # train classifier\n",
    "    clf.fit(vector_X, y)\n",
    "    calibrated_clf.fit(vector_X, y)\n",
    "\n",
    "    # predict labels for unlabelled set\n",
    "    y_pred = calibrated_clf.predict(unlabelled_X)\n",
    "\n",
    "    # get confidence scores\n",
    "    conf_scores = calibrated_clf.predict_proba(unlabelled_X)\n",
    "    print(\"scores\", conf_scores) # this is the confidence score for each class and if it is 0, 1 it is determining the class immediately\n",
    "\n",
    "    # get indices of high confidence predictions\n",
    "    high_conf_indices = np.where(np.max(conf_scores, axis=1) > conf_thresh)[0]\n",
    "    print(\"Number of high confidence predictions:\", len(high_conf_indices))\n",
    "\n",
    "    if len(high_conf_indices) == 0:\n",
    "        print(\"No high confidence predictions left\", i)\n",
    "        break\n",
    "\n",
    "    # add high confidence predictions to seed set\n",
    "    X = np.concatenate((X, unlabelled_set.iloc[high_conf_indices]['text']))\n",
    "    y = np.concatenate((y, y_pred[high_conf_indices]))\n",
    "    # remove high confidence predictions from unlabelled set\n",
    "    unlabelled_set = unlabelled_set.drop(unlabelled_set.index[high_conf_indices])\n",
    "\n",
    "    if (unlabelled_set.shape[0] == 0):\n",
    "        print(\"No more unlabelled data left\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Confusion matrix:\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       1.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sehrmoosabhoy/Documents/GitHub/COMP550/final-project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sehrmoosabhoy/Documents/GitHub/COMP550/final-project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sehrmoosabhoy/Documents/GitHub/COMP550/final-project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sehrmoosabhoy/Documents/GitHub/COMP550/final-project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sehrmoosabhoy/Documents/GitHub/COMP550/final-project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sehrmoosabhoy/Documents/GitHub/COMP550/final-project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# test the classifier\n",
    "X_test = test_data['text']\n",
    "y_test = test_data['sentiment']\n",
    "\n",
    "vector_X_test = vectorizer.transform(X_test)\n",
    "y_pred = calibrated_clf.predict(vector_X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
